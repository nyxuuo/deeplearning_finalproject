# DEEP LEARNING FINAL PROJECT
# Mental Health Text Classification using DistilBERT, BERT, and RoBERTa

## Full google drive link:
ğŸ”— [FINALPROJECT_DEEPLEARNING](https://drive.google.com/drive/folders/1jcaEpzCvAloIWYjkwoNsH087PG773ei-?usp=sharing)

---

This project aims to **predict mental health categories from user-written text** using three state-of-the-art Transformer models:

- **DistilBERT**
- **BERT-base**
- **RoBERTa-base**

The app classifies text into **7 mental health condition labels**:
```
0: "Normal"
1: "Depression"
2: "Suicidal"
3: "Anxiety"
4: "Bipolar"
5: "Stress"
6: "Personality Disorder"
```
This project includes **dataset preprocessing**, **model training**, **evaluation**, and a **streamlit web app (ran locally or on cloudfare in google colab)**.


## ğŸ¯ Project Goals

This project was built to:

- Detect mental health predictions/indications from user input (written text)
- Compare model performance (DistilBERT vs BERT vs RoBERTa)  
- Evaluate classification quality using F1-score and confusion matrix  
- Deploy an interactive demo using Streamlit  


## ğŸ§  Model Overview

### **DistilBERT**
- a lighter and faster version of BERT  
- 40% smaller, 60% faster    
- Works best for **real-time applications**

### **BERT-base**
- has a strong semantic understanding  
- good for complex text reasoning  
- more expensive (computationally)

### **RoBERTa-base**
- Optimized BERT (longer training, dynamic masking, larger batches)  
- Often achieves the highest accuracy 
- Most robust among the other 3


## ğŸ§ª Model Training & Evaluation

The notebook `model.ipynb` includes:

- Data cleaning  
- Tokenization  
- Fine-tuning all 3 models  
- Saving trained models  
- Evaluating using:
  - Classification report  
  - Confusion matrix  
  - Macro F1-score  
- Loss comparison (training & validation via forward pass)

To view more detail, see the code:  
ğŸ“„ **model.ipynb**

---

## ğŸš€ Running the Streamlit App (on google colab or locally)
> It is recommended to run this app on Google Colab, as the application, training process was also made fully in Google Colab

### **FOR GOOGLE COLAB**
â€¼ï¸ **PLEASE ENSURE THE FILE STRUCTURE IS AS BELOW:**
```
deeplearning_finalproject/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ distilbert_trained/
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”œâ”€â”€ model.safetensors 
â”‚   â”‚   â””â”€â”€ tokenizer.json
â”‚   â”‚   â””â”€â”€ etc..
â”‚   â”‚
â”‚   â”œâ”€â”€ bert_trained/
â”‚   â””â”€â”€ roberta_trained/
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ mental_health_dataset_augmented.csv
â”‚
â””â”€â”€ model.ipynb
```



Then, run the app by launching the app.py (or preferably app.ipynb, and execute all cell), include installing cloudfare & running the streamlit:
```
!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb

!dpkg -i cloudflared-linux-amd64.deb

!streamlit run /content/drive/MyDrive/FINPRO_DEEPLEARNING/app/app.py --server.port 8501 &>/dev/null &

!cloudflared tunnel --url http://localhost:8501 --no-autoupdate
```

After running the tunnel, it will show a link to access the streamlit app (usually in a format of xxx.trycloudfare.com)


### **RUN ON LOCAL**

###**1. CLONE REPO**
```
git clone https://github.com/nyxuuo/deeplearning_finalproject.git
cd deeplearning_finalproject
```

or clone using Github Desktop

### **2. Make Virtual Env and Install dependencies**
```
pip install streamlit torch transformers
```

or install from file: **requirements.txt**

## **3. Download MODEL from Google Drive**
[Click here to download the model](https://drive.google.com/drive/folders/1-_lgZsWNAplRe4scNaO6M1VHPd1mWBHp?usp=sharing)

â€¼ï¸ **IMPORTANT:** File structure must be made like this:
```
deeplearning_finalproject/
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ distilbert_trained/
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”œâ”€â”€ model.safetensors 
â”‚   â”‚   â””â”€â”€ tokenizer.json
â”‚   â”‚   â””â”€â”€ etc..
â”‚   â”‚
â”‚   â”œâ”€â”€ bert_trained/
â”‚   â””â”€â”€ roberta_trained/
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ mental_health_dataset_augmented.csv
â”‚
â””â”€â”€ model.ipynb
```
...and the model name should be the same (don't edit the model name!)

## **4. Check & adjust the path in app/app.py**

### **5. Run the app**
Run the app by doing:
``` 
streamlit run app/app.py
```

It will show a **Local URL**, and can be accessed.



